---
title: "p8105_hw5_bf2506"
author: "bf2506"
date: "2022-11-15"
output: github_document
---
```{r load package, message=FALSE, warning=FALSE}
library(tidyverse)
```

### Problem 2

```{r read homi_data}
homi_data = 
  read.csv("./data/homicide-data.csv") %>%
  janitor::clean_names()
```
**Describe the raw data:**

* The dataset has `r ncol(homi_data)` variables and `r nrow(homi_data)` observations.

  * "uid"(the abbreviation of city - number); "reported_date"
  
  * "victim_last"(last name of victim); "victim_first"(first name of victim); "victim_race"; "victim_age"; "victim_sex"
  
  * "city"; "state"; "lat"(latitude); "lon"(longitude); 
  
  * "disposition": 
    * Closed by arrest when *police reported that to be the case*
    * Closed without arrest when *police reported that to be “exceptionally cleared.”* Those are cases in which there is sufficient evidence but an arrest is not possible, for example, if the suspect has died.
    * Open/No arrest: *All other cases* were classified as having no arrest.

##### Part A

Create a city_state variable and then summarize within cities to obtain the total number of homicides and the number of unsolved homicides.

```{r message=FALSE, warning=FALSE}
homi_data = 
  homi_data %>% 
  mutate(city_state = paste(city, state, sep = ", ", collapse = NULL))

total_df = 
  homi_data %>% 
  group_by(city_state) %>% 
  summarize(total_number_homicide = n())

unsolved_df = 
  homi_data %>%
  filter(disposition != "Closed by arrest") %>% 
  group_by(city_state) %>% 
  summarize(number_unsolved_homicide = n())

total_unsolved_df = 
  left_join(total_df, unsolved_df) %>% 
  replace(is.na(.), 0)
```
*Tulsa, AL doesn't have a unsolved homicide, so it is not included in unsolved_df.*

##### Part B

For the city of Baltimore, MD, use the prop.test function to estimate the proportion of homicides that are unsolved; save the output of prop.test as an R object, apply the broom::tidy to this object and pull the estimated proportion and confidence intervals from the resulting tidy dataframe.

```{r message=FALSE, warning=FALSE}
balt_prop = 
  prop.test(1825, 2827, p = NULL, 
            alternative = "two.sided", conf.level = 0.95, correct = TRUE)
balt_prop

balt_prop_tibble = broom::tidy(balt_prop)
balt_prop_tibble

balt_prop_tibble %>% pull(estimate)
balt_prop_tibble %>% pull(conf.low)
balt_prop_tibble %>% pull(conf.high)
balt_prop_tibble %>% mutate(ci = paste("(", round(conf.low, 4), ",", round(conf.high, 4), ")")) %>% pull(ci)
```

##### Part C

Run prop.test for every city. Extract *the proportion of unsolved homicides* and *the confidence interval*. Do this within a “tidy” pipeline, making use of purrr::map, purrr::map2, list columns and unnest as necessary to create a tidy dataframe with estimated proportions and CIs for each city.

```{r message=FALSE, warning=FALSE}
prop_df = 
  total_unsolved_df %>% 
  mutate(result = purrr::map2(.x = number_unsolved_homicide, .y = total_number_homicide, ~broom::tidy(prop.test(x = .x, n = .y, alternative = "two.sided", conf.level = 0.95, correct = TRUE)))) %>% 
  unnest(result) %>% 
  select(city_state, estimate, conf.low, conf.high) %>% 
  mutate(confidence_interval = paste("(", round(conf.low, 4), ",", round(conf.high, 4), ")"))

prop_df
```
Considering the total number of homicides is 1 and the number of unsolved homicides is 0 in Tulsa, AL, the data is too small and insufficient in prop.test. We should pay attention to Tulsa, AL data.

##### Part C

Create a plot that shows the estimates and CIs for each city – check out geom_errorbar for a way to add error bars based on the upper and lower limits. Organize cities according to the proportion of unsolved homicides
```{r}
Estimates_CIs_Plot = 
  prop_df %>% 
  filter(city_state != "Tulsa, AL") %>% 
  ggplot(aes(x = reorder(city_state, estimate), y = estimate)) + 
  geom_point() +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high)) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(title = "Estimate And CI Of Proportion Of Unsolved Homicides For Each City", x = "City, State", y = "Estimate / CI")

Estimates_CIs_Plot
```
Since I discussed aboved, the  total number of homicides and the number of unsolved homicides in Tulsa, AL are not sufficient and enough to analyze and run a prop.test, I drop this data when making the "Estimate And CI Of Proportion Of Unsolved Homicides For Each City" plot.

### Problem 3

```{r}
set.seed(1)
```

##### Part A 

Generate 5000 datasets from the model(x ~ normal(mu, sigma)). For each dataset, save μ_cap and the p-value arising from t.test(significance level = 0,05)
```{r}
output = vector("list", 5000)

for (i in 1:5000) {
  output[[i]] = 
    broom::tidy(t.test( x = rnorm(n = 30, mean = 0, sd = 5), alternative = "two.sided", mu = 0, paired = FALSE, conf.level = 0.95)) %>% 
    select(estimate, p.value) %>% 
    rename(mu_cap = estimate)
}

sim_results_0 = bind_rows(output)
sim_results_0
```

##### Part B

```{r}
sim_mu = function(mu) {
  output = vector("list", 5000)
  
  for (i in 1:5000) {
  output[[i]] = 
    broom::tidy(t.test( x = rnorm(n = 30, mean = mu, sd = 5), alternative = "two.sided", mu = 0, paired = FALSE, conf.level = 0.95)) %>% 
    select(estimate, p.value) %>% 
    rename(mu_cap = estimate) }

sim_results_mu = bind_rows(output)
}
```

Repeat for mu=1,2,3,4,5,6
```{r}
sim_df = 
  expand_grid(
    mu = 0:6,
    iter = 1
  ) %>% 
  mutate(
    estimate_df = map(mu, sim_mu)
  ) %>% 
  unnest(estimate_df)
```

##### Part C
Make a plot showing the proportion of times the null was rejected (the power of the test) on the y axis and the true value of μ on the x axis. Describe the association between effect size and power.
```{r message=FALSE, warning=FALSE}
Power_Truemu_Plot = 
  sim_df %>% 
  filter(p.value <= 0.05) %>% 
  group_by(mu) %>% 
  summarize(times = n()) %>% 
  ggplot(aes(x = as.factor(mu), y = times/5000)) + 
  geom_point(alpha = .6) +
  labs(title = "The Power Of The Test Of Every True MU", x = "True Value Of Mu", y = "Proportion Of Times Null Was Rejected ")

Power_Truemu_Plot
```
* Describe the association between effect size and power.
The effect size is the difference between the true mu and the mu we assumed (mu = 0 in this situation), so when the true mu goes from 0 to 6, the effect size increases, then we found the power of the test also increases. We can conclude that when everything else doesn't change, the power of test will increase if the effect size increases.
